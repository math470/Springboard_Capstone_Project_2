{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Top'></a>\n",
    "\n",
    "# Yelp Recommender System Project\n",
    "## Part 3 Recommender System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview\n",
    "\n",
    "1. <a href='#1'>Data Preparation for Recommender system</a>\n",
    "1. <a href='#2'>Collaborative filtering</a>\n",
    "1. <a href='#3'>Content-based filtering</a> \n",
    "\n",
    "_The datasets were cleaned and explored in the data wrangling and EDA parts of this project (see Data wrangling and EDA notebooks for details). Note that the datasets used here contain only __food and restaurant__ related businesses, users, and reviews._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# Surprise packages\n",
    "from surprise import Reader\n",
    "from surprise import Dataset\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection import GridSearchCV\n",
    "\n",
    "from surprise import NormalPredictor\n",
    "from surprise import BaselineOnly\n",
    "from surprise import SVD\n",
    "from surprise import SVDpp\n",
    "from surprise import NMF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1'></a>\n",
    "### Data Preparation for Recommender system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\math4\\AppData\\Local\\conda\\conda\\envs\\Springboard\\lib\\site-packages\\numpy\\lib\\arraysetops.py:472: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('reviews_business_user_info.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>date</th>\n",
       "      <th>business_name</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>city_state</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>price_range</th>\n",
       "      <th>categories</th>\n",
       "      <th>user_name</th>\n",
       "      <th>yelping_since</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>x7mDIiDB3jEiPGPHOmDzyw</td>\n",
       "      <td>msQe1u7Z_XuqjGoqhB0J5g</td>\n",
       "      <td>iCQpiavjjPzJ5_3gPD5Ebg</td>\n",
       "      <td>2</td>\n",
       "      <td>2011-02-25</td>\n",
       "      <td>Secret Pizza</td>\n",
       "      <td>Las Vegas</td>\n",
       "      <td>NV</td>\n",
       "      <td>Las Vegas, NV</td>\n",
       "      <td>36.109837</td>\n",
       "      <td>-115.174212</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['Pizza', 'Restaurants']</td>\n",
       "      <td>Melissa</td>\n",
       "      <td>2011-02-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dDl8zu1vWPdKGihJrwQbpw</td>\n",
       "      <td>msQe1u7Z_XuqjGoqhB0J5g</td>\n",
       "      <td>pomGBqfbxcqPv14c3XH-ZQ</td>\n",
       "      <td>5</td>\n",
       "      <td>2012-11-13</td>\n",
       "      <td>Leticia's Mexican Cocina</td>\n",
       "      <td>Las Vegas</td>\n",
       "      <td>NV</td>\n",
       "      <td>Las Vegas, NV</td>\n",
       "      <td>36.298875</td>\n",
       "      <td>-115.280088</td>\n",
       "      <td>2.0</td>\n",
       "      <td>['Restaurants', 'Mexican', 'Bars', 'Nightlife']</td>\n",
       "      <td>Melissa</td>\n",
       "      <td>2011-02-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LZp4UX5zK3e-c5ZGSeo3kA</td>\n",
       "      <td>msQe1u7Z_XuqjGoqhB0J5g</td>\n",
       "      <td>jtQARsP6P-LbkyjbO1qNGg</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-10-23</td>\n",
       "      <td>H&amp;H BBQ Plus 2</td>\n",
       "      <td>Las Vegas</td>\n",
       "      <td>NV</td>\n",
       "      <td>Las Vegas, NV</td>\n",
       "      <td>36.241809</td>\n",
       "      <td>-115.234495</td>\n",
       "      <td>2.0</td>\n",
       "      <td>['American (New)', 'Barbeque', 'Restaurants']</td>\n",
       "      <td>Melissa</td>\n",
       "      <td>2011-02-24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                review_id                 user_id             business_id  \\\n",
       "0  x7mDIiDB3jEiPGPHOmDzyw  msQe1u7Z_XuqjGoqhB0J5g  iCQpiavjjPzJ5_3gPD5Ebg   \n",
       "1  dDl8zu1vWPdKGihJrwQbpw  msQe1u7Z_XuqjGoqhB0J5g  pomGBqfbxcqPv14c3XH-ZQ   \n",
       "2  LZp4UX5zK3e-c5ZGSeo3kA  msQe1u7Z_XuqjGoqhB0J5g  jtQARsP6P-LbkyjbO1qNGg   \n",
       "\n",
       "   stars        date             business_name       city state  \\\n",
       "0      2  2011-02-25              Secret Pizza  Las Vegas    NV   \n",
       "1      5  2012-11-13  Leticia's Mexican Cocina  Las Vegas    NV   \n",
       "2      1  2014-10-23            H&H BBQ Plus 2  Las Vegas    NV   \n",
       "\n",
       "      city_state   latitude   longitude  price_range  \\\n",
       "0  Las Vegas, NV  36.109837 -115.174212          1.0   \n",
       "1  Las Vegas, NV  36.298875 -115.280088          2.0   \n",
       "2  Las Vegas, NV  36.241809 -115.234495          2.0   \n",
       "\n",
       "                                        categories user_name yelping_since  \n",
       "0                         ['Pizza', 'Restaurants']   Melissa    2011-02-24  \n",
       "1  ['Restaurants', 'Mexican', 'Bars', 'Nightlife']   Melissa    2011-02-24  \n",
       "2    ['American (New)', 'Barbeque', 'Restaurants']   Melissa    2011-02-24  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4017884 entries, 0 to 4017883\n",
      "Data columns (total 15 columns):\n",
      "review_id        object\n",
      "user_id          object\n",
      "business_id      object\n",
      "stars            int64\n",
      "date             object\n",
      "business_name    object\n",
      "city             object\n",
      "state            object\n",
      "city_state       object\n",
      "latitude         float64\n",
      "longitude        float64\n",
      "price_range      float64\n",
      "categories       object\n",
      "user_name        object\n",
      "yelping_since    object\n",
      "dtypes: float64(3), int64(1), object(11)\n",
      "memory usage: 490.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selecting one metropolitan area"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For building a recommender system, I will use food and restaurant businesses only in one metropolitan area for several reasons. First of all, people normally want to have recommendations in some areas they plan to visit. Moreover, if all cities are used, the matrix by users (rows) and businesses (columns) becomes very sparse and this makes it hard to predict stars.  \n",
    "\n",
    "The city with the most number of reviews was Las Vegas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Las Vegas, NV          1139203\n",
       "Phoenix, AZ             408423\n",
       "Toronto, ON             380025\n",
       "Scottsdale, AZ          217414\n",
       "Charlotte, NC           198690\n",
       "Pittsburgh, PA          157270\n",
       "MontrÃ©al, QC           115208\n",
       "Tempe, AZ               115027\n",
       "Henderson, NV           109831\n",
       "Mesa, AZ                 88576\n",
       "Chandler, AZ             86319\n",
       "Cleveland, OH            81433\n",
       "Madison, WI              71896\n",
       "Gilbert, AZ              68186\n",
       "Calgary, AB              63940\n",
       "Glendale, AZ             53566\n",
       "Mississauga, ON          39518\n",
       "Markham, ON              39319\n",
       "Peoria, AZ               29418\n",
       "North Las Vegas, NV      25355\n",
       "Name: city_state, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.city_state.value_counts()[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I noticed some of the other cities above are also in the [Las Vegas–Henderson–Paradise, NV  metropolitan area](https://en.wikipedia.org/wiki/Las_Vegas%E2%80%93Henderson%E2%80%93Paradise,_NV_Metropolitan_Statistical_Area). The cities belong to the metropolitan area are Henderson,  North Las Vegas, Paradise, Las Vegas, and Boulder City and I will include reviews in all of these cities. \n",
    "\n",
    "In the EDA part, I already transformed 5 kinds of strings representing Las Vegas into 'Las Vegas'. 'Henderson and Las vegas' actually  representing Henderson was also fixed. Here, I will further clean up strings for North Las Vegas. I did not find any multiple strings for Paradise and Boulder City. I will also check whether there are any same name cities in other states."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fixing city names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Las Vegas, NV    1139203\n",
       "Name: city_state, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.city=='Las Vegas'].city_state.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Paradise, NV    110\n",
       "Name: city_state, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.city=='Paradise'].city_state.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Boulder City, NV    5746\n",
       "Name: city_state, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.city=='Boulder City'].city_state.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Henderson, NV    109831\n",
       "Henderson, VA         3\n",
       "Name: city_state, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.city=='Henderson'].city_state.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is Henderson in Virginia! Thus, I need to use the city_state column I made to select the 5 cities in my interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "North Las Vegas, NV    25355\n",
       "N. Las Vegas, NV         287\n",
       "N Las Vegas, NV          113\n",
       "Name: city_state, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.city.isin(['N Las Vegas', 'N. Las Vegas', 'North Las Vegas'])].city_state.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They are altogether 25755 and 'N Las Vegas' and 'N. Las Vegas'(400 of them) will be fixed to 'North Las Vegas'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function from the EDA part\n",
    "def unify_city_names(df, col_name, possible_names, correct_name):\n",
    "    '''\n",
    "    This function correct all possible city names to a correct name\n",
    "    '''\n",
    "    correct_dict = dict(zip(possible_names,[correct_name]*len(possible_names)))\n",
    "    print(correct_dict)\n",
    "    df[col_name]=df[col_name].replace(correct_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'N Las Vegas': 'North Las Vegas', 'N. Las Vegas': 'North Las Vegas'}\n"
     ]
    }
   ],
   "source": [
    "unify_city_names(df, 'city', ['N Las Vegas', 'N. Las Vegas'], 'North Las Vegas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(df.city.isin(['N Las Vegas', 'N. Las Vegas'])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25755"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(df.city=='North Las Vegas')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number looks correct! I also need to fix the city_state column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25355"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(df.city_state=='North Las Vegas, NV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(df.city_state.isin(['N Las Vegas, NV', 'N. Las Vegas, NV']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'N Las Vegas, NV': 'North Las Vegas, NV', 'N. Las Vegas, NV': 'North Las Vegas, NV'}\n"
     ]
    }
   ],
   "source": [
    "unify_city_names(df, 'city_state', ['N Las Vegas, NV', 'N. Las Vegas, NV'], 'North Las Vegas, NV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(df.city_state.isin(['N Las Vegas, NV', 'N. Las Vegas, NV']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25755"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(df.city_state=='North Las Vegas, NV')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Selecting reviews in those cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_states_Vegas = ['Las Vegas, NV','North Las Vegas, NV','Paradise, NV',\n",
    "                    'Boulder City, NV', 'Henderson, NV']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1280645"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1139203+110+5746+109831+25755"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1280645"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Vegas = df[df.city_state.isin(city_states_Vegas)]\n",
    "len(df_Vegas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_Vegas) == 1139203+110+5746+109831+25755"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of reviews, 1,280,645, looks alright!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "422409"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of users\n",
    "df_Vegas.user_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9674"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of businesses\n",
    "df_Vegas.business_id.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Las Vegas reviews have \n",
    "- 1,280,645 reviews\n",
    "- 422,409 users  \n",
    "- 9,674 businesses "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save Vegas reviews\n",
    "#df_Vegas.to_csv('reviews_business_user_info_Vegas.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selecting businesses and users with enough reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ids_with_enough_reviews(df, column, threshold):\n",
    "    review_counts = df[column].value_counts() \n",
    "    return review_counts[review_counts >= threshold].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20340"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(df_Vegas.user_id.value_counts()>=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ids_10more = ids_with_enough_reviews(df_Vegas, 'user_id', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20340"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Vegas[df_Vegas.user_id.isin(user_ids_10more)].user_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6268"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(df_Vegas.business_id.value_counts()>=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "business_ids_20more = ids_with_enough_reviews(df_Vegas, 'business_id', 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6268"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Vegas[df_Vegas.business_id.isin(business_ids_20more)].business_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "493658"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_Vegas[(df_Vegas.business_id.isin(business_ids_20more))&(df_Vegas.user_id.isin(user_ids_10more))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Vegas_over_10_20 = df_Vegas[(df_Vegas.business_id.isin(business_ids_20more))&(df_Vegas.user_id.isin(user_ids_10more))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20340, 6266, 493658)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Vegas_over_10_20.user_id.nunique(), df_Vegas_over_10_20.business_id.nunique(), len(df_Vegas_over_10_20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After removing users with less than 10 reviews and businesses with less than 20 reviews, the dataset has\n",
    "- 493,658 reviews\n",
    "- 20,340 users\n",
    "- 6,266 businesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Vegas_over_10_20.to_csv('reviews_business_user_info_Vegas_over_10_20.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2'></a>\n",
    "### Collaborative Filtering\n",
    "\n",
    "Now it's time to build recommender systems!\n",
    "\n",
    "I am going to use the recommender system package called [Surprise](https://surprise.readthedocs.io/en/stable/index.html) for collaborative filtering algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split test and training sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(df_Vegas_over_10_20[['user_id', 'business_id', 'stars']], reader)\n",
    "raw_ratings = data.raw_ratings\n",
    "\n",
    "# shuffle ratings \n",
    "random.Random(32).shuffle(raw_ratings)\n",
    "\n",
    "# 90% training and 10% test data\n",
    "threshold = int(.9 * len(raw_ratings))\n",
    "train_raw_ratings = raw_ratings[:threshold]\n",
    "test_raw_ratings = raw_ratings[threshold:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('U4INQZOPSUaj8hMjLlZ3KA', '4JNXUYY8wbaaDmk3BPzlWw', 3.0, None),\n",
       " ('cg2P244yON3-_GXWkgAgsw', 'umXvdus9LbC6oxtLdXelFQ', 4.0, None),\n",
       " ('YHdXkAmndIfuIczWOnsjeQ', '7HIa2lYy5jgcZuADlRjKSg', 1.0, None),\n",
       " ('CstEf6M4JSom9Msm0qIYew', 'wdOOK3K6vzQy1d_OIk-U9w', 3.0, None),\n",
       " ('Cwkkowhq9MZue1Xyk57BMg', '7sPNbCx7vGAaH7SbNPZ6oA', 4.0, None)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_ratings[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_test_algorithm(train_set, test_set, algorithm, param_grid, n_cv, cv_result=True):\n",
    "\n",
    "    data.raw_ratings = train_set  # data is now the set A\n",
    "\n",
    "    # grid search cross validation\n",
    "    gs = GridSearchCV(algorithm, param_grid, measures=['rmse'], cv=n_cv, n_jobs=-1)\n",
    "    gs.fit(data)\n",
    "    best_algo = gs.best_estimator['rmse']\n",
    "    # hyper-parameters for the best RMSE score\n",
    "    best_params = gs.best_params['rmse']\n",
    "    print(\"Best hyper-parameters:\", best_params)\n",
    "    print()\n",
    "    \n",
    "    # show RMSE for each hyper-parameter combination if cv_result=True\n",
    "    # if cv_result=False, only show the RMSE for the best combination\n",
    "    if cv_result:\n",
    "        print(\"Training set RMSE for each hyper-parameter combination:\")\n",
    "    else:\n",
    "        print(\"Training set RMSE for the best hyper-parameter combination:\")\n",
    "    means = gs.cv_results['mean_test_rmse']\n",
    "    stds = gs.cv_results['std_test_rmse']\n",
    "    parameters = gs.cv_results['params']\n",
    "    for mean, std, params in zip(means, stds, parameters):\n",
    "        if (cv_result)|(params == best_params):\n",
    "            print(\"%0.4f (+/-%0.04f) for %r\" % (mean, std * 2, params))                \n",
    "    print()\n",
    "\n",
    "    # Compute performance on the whole training set \n",
    "    trainset = data.build_full_trainset()\n",
    "    best_algo.fit(trainset)\n",
    "    pred = best_algo.test(trainset.build_testset())\n",
    "#    print('Train set', end='  ')\n",
    "#    accuracy.rmse(pred)\n",
    "    \n",
    "    # Compute performance on test set\n",
    "    testset = data.construct_testset(test_set)  # testset is now the set B\n",
    "    pred = best_algo.test(testset)\n",
    "    print('Test set', end='  ')\n",
    "    accuracy.rmse(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Surprise GridSearchCV accepts only classes, so I added all hyper-parameters (e.g., random_state) of an algorithm as a grid search parameter whether it is tuned or not. https://github.com/NicolasHug/Surprise/issues/212"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NormalPredictor Algorithm\n",
    "\n",
    "NormalPredictor predicts ratings randomly from the normal distribution with mean and standard deviation estimated by the training set. This is a good base model to be compared with more complex models.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyper-parameters: {}\n",
      "\n",
      "Training set RMSE for each hyper-parameter combination:\n",
      "1.6269 (+/-0.0041) for {}\n",
      "\n",
      "Test set  RMSE: 1.6317\n",
      "Wall time: 26.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "param_grid = {}\n",
    "training_test_algorithm(train_raw_ratings, test_raw_ratings, NormalPredictor, param_grid, n_cv=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyper-parameters: {}\n",
      "\n",
      "Training set RMSE for each hyper-parameter combination:\n",
      "1.1062 (+/-0.0029) for {}\n",
      "\n",
      "Estimating biases using als...\n",
      "Test set  RMSE: 1.0941\n",
      "Wall time: 27 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "param_grid = {}\n",
    "training_test_algorithm(train_raw_ratings, test_raw_ratings, BaselineOnly, param_grid, n_cv=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The baseline model is much better than the Normal predictor! \n",
    "- By default, the above used Alternating Least Squares (ALS) and I am going to check how Stochastic Gradient Descent (SGD) peforms.\n",
    "- I also tried n_cv=5 for many algorithms, but it did not improve the performance on the test set although the performanceo on the training set is a little better with 5. Thus, I decided use 3 since it saves more time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyper-parameters: {'bsl_options': {'method': 'sgd'}}\n",
      "\n",
      "Training set RMSE for each hyper-parameter combination:\n",
      "1.1063 (+/-0.0027) for {'bsl_options': {'method': 'als'}}\n",
      "1.1005 (+/-0.0025) for {'bsl_options': {'method': 'sgd'}}\n",
      "\n",
      "Estimating biases using sgd...\n",
      "Test set  RMSE: 1.0891\n",
      "Wall time: 42.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "param_grid = {'bsl_options':{'method': ['als','sgd']}}\n",
    "training_test_algorithm(train_raw_ratings, test_raw_ratings, BaselineOnly, param_grid, n_cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyper-parameters: {'bsl_options': {'method': 'sgd'}}\n",
      "\n",
      "Training set RMSE for each hyper-parameter combination:\n",
      "1.1064 (+/-0.0035) for {'bsl_options': {'method': 'als'}}\n",
      "Training set RMSE for each hyper-parameter combination:\n",
      "1.1006 (+/-0.0034) for {'bsl_options': {'method': 'sgd'}}\n",
      "\n",
      "Estimating biases using sgd...\n",
      "Test set  RMSE: 1.0891\n",
      "Wall time: 43.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "param_grid = {'bsl_options':{'method': ['als','sgd']}}\n",
    "training_test_algorithm(train_raw_ratings, test_raw_ratings, BaselineOnly, param_grid, n_cv=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SGD is slightly better (lower RMSE) than the default method ALS for the baseline model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyper-parameters: {'bsl_options': {'method': 'sgd', 'n_epochs': 20}}\n",
      "\n",
      "Training set RMSE for each hyper-parameter combination:\n",
      "1.1078 (+/-0.0031) for {'bsl_options': {'method': 'sgd', 'n_epochs': 10}}\n",
      "1.0999 (+/-0.0025) for {'bsl_options': {'method': 'sgd', 'n_epochs': 20}}\n",
      "1.1002 (+/-0.0024) for {'bsl_options': {'method': 'sgd', 'n_epochs': 30}}\n",
      "\n",
      "Estimating biases using sgd...\n",
      "Test set  RMSE: 1.0891\n",
      "Wall time: 59.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "param_grid = {'bsl_options':{'method': ['sgd'],'n_epochs': [10,20,30]}}\n",
    "training_test_algorithm(train_raw_ratings, test_raw_ratings, BaselineOnly, param_grid, n_cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyper-parameters: {'bsl_options': {'method': 'sgd', 'n_epochs': 30, 'reg': 0.1, 'learning_rate': 0.005}}\n",
      "\n",
      "Training set RMSE for each hyper-parameter combination:\n",
      "1.1130 (+/-0.0023) for {'bsl_options': {'method': 'sgd', 'n_epochs': 20, 'reg': 0.05, 'learning_rate': 0.002}}\n",
      "1.1002 (+/-0.0024) for {'bsl_options': {'method': 'sgd', 'n_epochs': 20, 'reg': 0.05, 'learning_rate': 0.005}}\n",
      "1.1024 (+/-0.0026) for {'bsl_options': {'method': 'sgd', 'n_epochs': 20, 'reg': 0.05, 'learning_rate': 0.01}}\n",
      "1.1137 (+/-0.0022) for {'bsl_options': {'method': 'sgd', 'n_epochs': 20, 'reg': 0.1, 'learning_rate': 0.002}}\n",
      "1.1004 (+/-0.0023) for {'bsl_options': {'method': 'sgd', 'n_epochs': 20, 'reg': 0.1, 'learning_rate': 0.005}}\n",
      "1.1017 (+/-0.0024) for {'bsl_options': {'method': 'sgd', 'n_epochs': 20, 'reg': 0.1, 'learning_rate': 0.01}}\n",
      "1.1146 (+/-0.0021) for {'bsl_options': {'method': 'sgd', 'n_epochs': 20, 'reg': 0.15, 'learning_rate': 0.002}}\n",
      "1.1009 (+/-0.0022) for {'bsl_options': {'method': 'sgd', 'n_epochs': 20, 'reg': 0.15, 'learning_rate': 0.005}}\n",
      "1.1015 (+/-0.0023) for {'bsl_options': {'method': 'sgd', 'n_epochs': 20, 'reg': 0.15, 'learning_rate': 0.01}}\n",
      "1.1051 (+/-0.0024) for {'bsl_options': {'method': 'sgd', 'n_epochs': 30, 'reg': 0.05, 'learning_rate': 0.002}}\n",
      "1.1002 (+/-0.0025) for {'bsl_options': {'method': 'sgd', 'n_epochs': 30, 'reg': 0.05, 'learning_rate': 0.005}}\n",
      "1.1059 (+/-0.0026) for {'bsl_options': {'method': 'sgd', 'n_epochs': 30, 'reg': 0.05, 'learning_rate': 0.01}}\n",
      "1.1057 (+/-0.0023) for {'bsl_options': {'method': 'sgd', 'n_epochs': 30, 'reg': 0.1, 'learning_rate': 0.002}}\n",
      "1.0999 (+/-0.0024) for {'bsl_options': {'method': 'sgd', 'n_epochs': 30, 'reg': 0.1, 'learning_rate': 0.005}}\n",
      "1.1045 (+/-0.0024) for {'bsl_options': {'method': 'sgd', 'n_epochs': 30, 'reg': 0.1, 'learning_rate': 0.01}}\n",
      "1.1065 (+/-0.0022) for {'bsl_options': {'method': 'sgd', 'n_epochs': 30, 'reg': 0.15, 'learning_rate': 0.002}}\n",
      "1.1001 (+/-0.0023) for {'bsl_options': {'method': 'sgd', 'n_epochs': 30, 'reg': 0.15, 'learning_rate': 0.005}}\n",
      "1.1038 (+/-0.0023) for {'bsl_options': {'method': 'sgd', 'n_epochs': 30, 'reg': 0.15, 'learning_rate': 0.01}}\n",
      "1.1015 (+/-0.0024) for {'bsl_options': {'method': 'sgd', 'n_epochs': 40, 'reg': 0.05, 'learning_rate': 0.002}}\n",
      "1.1018 (+/-0.0026) for {'bsl_options': {'method': 'sgd', 'n_epochs': 40, 'reg': 0.05, 'learning_rate': 0.005}}\n",
      "1.1083 (+/-0.0027) for {'bsl_options': {'method': 'sgd', 'n_epochs': 40, 'reg': 0.05, 'learning_rate': 0.01}}\n",
      "1.1019 (+/-0.0023) for {'bsl_options': {'method': 'sgd', 'n_epochs': 40, 'reg': 0.1, 'learning_rate': 0.002}}\n",
      "1.1012 (+/-0.0024) for {'bsl_options': {'method': 'sgd', 'n_epochs': 40, 'reg': 0.1, 'learning_rate': 0.005}}\n",
      "1.1065 (+/-0.0025) for {'bsl_options': {'method': 'sgd', 'n_epochs': 40, 'reg': 0.1, 'learning_rate': 0.01}}\n",
      "1.1027 (+/-0.0022) for {'bsl_options': {'method': 'sgd', 'n_epochs': 40, 'reg': 0.15, 'learning_rate': 0.002}}\n",
      "1.1010 (+/-0.0023) for {'bsl_options': {'method': 'sgd', 'n_epochs': 40, 'reg': 0.15, 'learning_rate': 0.005}}\n",
      "1.1054 (+/-0.0023) for {'bsl_options': {'method': 'sgd', 'n_epochs': 40, 'reg': 0.15, 'learning_rate': 0.01}}\n",
      "\n",
      "Estimating biases using sgd...\n",
      "Test set  RMSE: 1.0897\n",
      "Wall time: 7min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "param_grid = {'bsl_options':{'method': ['sgd'],'n_epochs': [20, 30, 40],\n",
    "                            'reg':[.05,.1,.15], 'learning_rate':[.002,.005,.01]}}\n",
    "training_test_algorithm(train_raw_ratings, test_raw_ratings, BaselineOnly, param_grid, n_cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyper-parameters: {'bsl_options': {'method': 'sgd', 'n_epochs': 30, 'reg': 0.1, 'learning_rate': 0.005}}\n",
      "\n",
      "Training set RMSE for each hyper-parameter combination:\n",
      "1.0999 (+/-0.0046) for {'bsl_options': {'method': 'sgd', 'n_epochs': 20, 'reg': 0.01, 'learning_rate': 0.005}}\n",
      "1.0999 (+/-0.0046) for {'bsl_options': {'method': 'sgd', 'n_epochs': 20, 'reg': 0.015, 'learning_rate': 0.005}}\n",
      "1.0999 (+/-0.0046) for {'bsl_options': {'method': 'sgd', 'n_epochs': 20, 'reg': 0.02, 'learning_rate': 0.005}}\n",
      "1.0998 (+/-0.0046) for {'bsl_options': {'method': 'sgd', 'n_epochs': 20, 'reg': 0.05, 'learning_rate': 0.005}}\n",
      "1.1000 (+/-0.0045) for {'bsl_options': {'method': 'sgd', 'n_epochs': 20, 'reg': 0.1, 'learning_rate': 0.005}}\n",
      "1.1006 (+/-0.0044) for {'bsl_options': {'method': 'sgd', 'n_epochs': 20, 'reg': 0.15, 'learning_rate': 0.005}}\n",
      "1.1015 (+/-0.0043) for {'bsl_options': {'method': 'sgd', 'n_epochs': 20, 'reg': 0.2, 'learning_rate': 0.005}}\n",
      "1.1005 (+/-0.0046) for {'bsl_options': {'method': 'sgd', 'n_epochs': 30, 'reg': 0.01, 'learning_rate': 0.005}}\n",
      "1.1004 (+/-0.0045) for {'bsl_options': {'method': 'sgd', 'n_epochs': 30, 'reg': 0.015, 'learning_rate': 0.005}}\n",
      "1.1003 (+/-0.0045) for {'bsl_options': {'method': 'sgd', 'n_epochs': 30, 'reg': 0.02, 'learning_rate': 0.005}}\n",
      "1.0999 (+/-0.0045) for {'bsl_options': {'method': 'sgd', 'n_epochs': 30, 'reg': 0.05, 'learning_rate': 0.005}}\n",
      "1.0996 (+/-0.0044) for {'bsl_options': {'method': 'sgd', 'n_epochs': 30, 'reg': 0.1, 'learning_rate': 0.005}}\n",
      "1.0998 (+/-0.0043) for {'bsl_options': {'method': 'sgd', 'n_epochs': 30, 'reg': 0.15, 'learning_rate': 0.005}}\n",
      "1.1004 (+/-0.0043) for {'bsl_options': {'method': 'sgd', 'n_epochs': 30, 'reg': 0.2, 'learning_rate': 0.005}}\n",
      "1.1026 (+/-0.0045) for {'bsl_options': {'method': 'sgd', 'n_epochs': 40, 'reg': 0.01, 'learning_rate': 0.005}}\n",
      "1.1025 (+/-0.0045) for {'bsl_options': {'method': 'sgd', 'n_epochs': 40, 'reg': 0.015, 'learning_rate': 0.005}}\n",
      "1.1023 (+/-0.0045) for {'bsl_options': {'method': 'sgd', 'n_epochs': 40, 'reg': 0.02, 'learning_rate': 0.005}}\n",
      "1.1016 (+/-0.0044) for {'bsl_options': {'method': 'sgd', 'n_epochs': 40, 'reg': 0.05, 'learning_rate': 0.005}}\n",
      "1.1009 (+/-0.0044) for {'bsl_options': {'method': 'sgd', 'n_epochs': 40, 'reg': 0.1, 'learning_rate': 0.005}}\n",
      "1.1008 (+/-0.0043) for {'bsl_options': {'method': 'sgd', 'n_epochs': 40, 'reg': 0.15, 'learning_rate': 0.005}}\n",
      "1.1010 (+/-0.0042) for {'bsl_options': {'method': 'sgd', 'n_epochs': 40, 'reg': 0.2, 'learning_rate': 0.005}}\n",
      "1.1048 (+/-0.0044) for {'bsl_options': {'method': 'sgd', 'n_epochs': 50, 'reg': 0.01, 'learning_rate': 0.005}}\n",
      "1.1046 (+/-0.0044) for {'bsl_options': {'method': 'sgd', 'n_epochs': 50, 'reg': 0.015, 'learning_rate': 0.005}}\n",
      "1.1044 (+/-0.0044) for {'bsl_options': {'method': 'sgd', 'n_epochs': 50, 'reg': 0.02, 'learning_rate': 0.005}}\n",
      "1.1035 (+/-0.0044) for {'bsl_options': {'method': 'sgd', 'n_epochs': 50, 'reg': 0.05, 'learning_rate': 0.005}}\n",
      "1.1024 (+/-0.0043) for {'bsl_options': {'method': 'sgd', 'n_epochs': 50, 'reg': 0.1, 'learning_rate': 0.005}}\n",
      "1.1020 (+/-0.0043) for {'bsl_options': {'method': 'sgd', 'n_epochs': 50, 'reg': 0.15, 'learning_rate': 0.005}}\n",
      "1.1020 (+/-0.0042) for {'bsl_options': {'method': 'sgd', 'n_epochs': 50, 'reg': 0.2, 'learning_rate': 0.005}}\n",
      "1.1084 (+/-0.0044) for {'bsl_options': {'method': 'sgd', 'n_epochs': 70, 'reg': 0.01, 'learning_rate': 0.005}}\n",
      "1.1081 (+/-0.0044) for {'bsl_options': {'method': 'sgd', 'n_epochs': 70, 'reg': 0.015, 'learning_rate': 0.005}}\n",
      "1.1078 (+/-0.0044) for {'bsl_options': {'method': 'sgd', 'n_epochs': 70, 'reg': 0.02, 'learning_rate': 0.005}}\n",
      "1.1065 (+/-0.0044) for {'bsl_options': {'method': 'sgd', 'n_epochs': 70, 'reg': 0.05, 'learning_rate': 0.005}}\n",
      "1.1049 (+/-0.0043) for {'bsl_options': {'method': 'sgd', 'n_epochs': 70, 'reg': 0.1, 'learning_rate': 0.005}}\n",
      "1.1040 (+/-0.0043) for {'bsl_options': {'method': 'sgd', 'n_epochs': 70, 'reg': 0.15, 'learning_rate': 0.005}}\n",
      "1.1036 (+/-0.0042) for {'bsl_options': {'method': 'sgd', 'n_epochs': 70, 'reg': 0.2, 'learning_rate': 0.005}}\n",
      "1.1115 (+/-0.0044) for {'bsl_options': {'method': 'sgd', 'n_epochs': 100, 'reg': 0.01, 'learning_rate': 0.005}}\n",
      "1.1112 (+/-0.0044) for {'bsl_options': {'method': 'sgd', 'n_epochs': 100, 'reg': 0.015, 'learning_rate': 0.005}}\n",
      "1.1108 (+/-0.0044) for {'bsl_options': {'method': 'sgd', 'n_epochs': 100, 'reg': 0.02, 'learning_rate': 0.005}}\n",
      "1.1091 (+/-0.0044) for {'bsl_options': {'method': 'sgd', 'n_epochs': 100, 'reg': 0.05, 'learning_rate': 0.005}}\n",
      "1.1071 (+/-0.0043) for {'bsl_options': {'method': 'sgd', 'n_epochs': 100, 'reg': 0.1, 'learning_rate': 0.005}}\n",
      "1.1058 (+/-0.0043) for {'bsl_options': {'method': 'sgd', 'n_epochs': 100, 'reg': 0.15, 'learning_rate': 0.005}}\n",
      "1.1050 (+/-0.0042) for {'bsl_options': {'method': 'sgd', 'n_epochs': 100, 'reg': 0.2, 'learning_rate': 0.005}}\n",
      "\n",
      "Estimating biases using sgd...\n",
      "Test set  RMSE: 1.0897\n",
      "Wall time: 11min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "param_grid = {'bsl_options':{'method': ['sgd'],'n_epochs': [20,30,40,50,70,100],\n",
    "                            'reg':[.01,.015,.02,.05,.1,.15,.2], 'learning_rate':[.005]}}\n",
    "training_test_algorithm(train_raw_ratings, test_raw_ratings, BaselineOnly, param_grid, n_cv=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVD algorithm\n",
    "\n",
    "[Easy explanation](https://medium.com/@m_n_malaeb/singular-value-decomposition-svd-in-recommender-systems-for-non-math-statistics-programming-4a622de653e9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyper-parameters: {'random_state': 32}\n",
      "\n",
      "Training set RMSE for each hyper-parameter combination:\n",
      "1.1151 (+/-0.0057) for {'random_state': 32}\n",
      "\n",
      "Test set  RMSE: 1.1066\n",
      "Wall time: 1min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "param_grid = {'random_state':[32]}\n",
    "training_test_algorithm(train_raw_ratings, test_raw_ratings, SVD, param_grid, n_cv=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVD without tuning hyper-parameters is not better than the baseline models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyper-parameters: {'n_epochs': 20, 'lr_all': 0.005, 'reg_all': 0.1, 'random_state': 32}\n",
      "\n",
      "Training set RMSE for each hyper-parameter combination:\n",
      "1.1367 (+/-0.0066) for {'n_epochs': 10, 'lr_all': 0.002, 'reg_all': 0.02, 'random_state': 32}\n",
      "1.1364 (+/-0.0066) for {'n_epochs': 10, 'lr_all': 0.002, 'reg_all': 0.05, 'random_state': 32}\n",
      "1.1364 (+/-0.0066) for {'n_epochs': 10, 'lr_all': 0.002, 'reg_all': 0.1, 'random_state': 32}\n",
      "1.1149 (+/-0.0063) for {'n_epochs': 10, 'lr_all': 0.005, 'reg_all': 0.02, 'random_state': 32}\n",
      "1.1133 (+/-0.0063) for {'n_epochs': 10, 'lr_all': 0.005, 'reg_all': 0.05, 'random_state': 32}\n",
      "1.1124 (+/-0.0063) for {'n_epochs': 10, 'lr_all': 0.005, 'reg_all': 0.1, 'random_state': 32}\n",
      "1.1147 (+/-0.0059) for {'n_epochs': 10, 'lr_all': 0.01, 'reg_all': 0.02, 'random_state': 32}\n",
      "1.1080 (+/-0.0059) for {'n_epochs': 10, 'lr_all': 0.01, 'reg_all': 0.05, 'random_state': 32}\n",
      "1.1045 (+/-0.0059) for {'n_epochs': 10, 'lr_all': 0.01, 'reg_all': 0.1, 'random_state': 32}\n",
      "1.1188 (+/-0.0065) for {'n_epochs': 20, 'lr_all': 0.002, 'reg_all': 0.02, 'random_state': 32}\n",
      "1.1177 (+/-0.0064) for {'n_epochs': 20, 'lr_all': 0.002, 'reg_all': 0.05, 'random_state': 32}\n",
      "1.1171 (+/-0.0064) for {'n_epochs': 20, 'lr_all': 0.002, 'reg_all': 0.1, 'random_state': 32}\n",
      "1.1148 (+/-0.0060) for {'n_epochs': 20, 'lr_all': 0.005, 'reg_all': 0.02, 'random_state': 32}\n",
      "1.1078 (+/-0.0059) for {'n_epochs': 20, 'lr_all': 0.005, 'reg_all': 0.05, 'random_state': 32}\n",
      "1.1042 (+/-0.0059) for {'n_epochs': 20, 'lr_all': 0.005, 'reg_all': 0.1, 'random_state': 32}\n",
      "1.1434 (+/-0.0055) for {'n_epochs': 20, 'lr_all': 0.01, 'reg_all': 0.02, 'random_state': 32}\n",
      "1.1213 (+/-0.0055) for {'n_epochs': 20, 'lr_all': 0.01, 'reg_all': 0.05, 'random_state': 32}\n",
      "1.1072 (+/-0.0057) for {'n_epochs': 20, 'lr_all': 0.01, 'reg_all': 0.1, 'random_state': 32}\n",
      "1.1129 (+/-0.0063) for {'n_epochs': 30, 'lr_all': 0.002, 'reg_all': 0.02, 'random_state': 32}\n",
      "1.1105 (+/-0.0063) for {'n_epochs': 30, 'lr_all': 0.002, 'reg_all': 0.05, 'random_state': 32}\n",
      "1.1092 (+/-0.0062) for {'n_epochs': 30, 'lr_all': 0.002, 'reg_all': 0.1, 'random_state': 32}\n",
      "1.1288 (+/-0.0057) for {'n_epochs': 30, 'lr_all': 0.005, 'reg_all': 0.02, 'random_state': 32}\n",
      "1.1130 (+/-0.0057) for {'n_epochs': 30, 'lr_all': 0.005, 'reg_all': 0.05, 'random_state': 32}\n",
      "1.1044 (+/-0.0058) for {'n_epochs': 30, 'lr_all': 0.005, 'reg_all': 0.1, 'random_state': 32}\n",
      "1.1586 (+/-0.0052) for {'n_epochs': 30, 'lr_all': 0.01, 'reg_all': 0.02, 'random_state': 32}\n",
      "1.1332 (+/-0.0053) for {'n_epochs': 30, 'lr_all': 0.01, 'reg_all': 0.05, 'random_state': 32}\n",
      "1.1136 (+/-0.0056) for {'n_epochs': 30, 'lr_all': 0.01, 'reg_all': 0.1, 'random_state': 32}\n",
      "\n",
      "Test set  RMSE: 1.0920\n",
      "Wall time: 9min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "param_grid = {'n_epochs':[10, 20, 30], 'lr_all': [0.002, 0.005,.01], \n",
    "              'reg_all': [0.02, 0.05, .1], 'random_state':[32]}\n",
    "training_test_algorithm(train_raw_ratings, test_raw_ratings, SVD, param_grid, n_cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyper-parameters: {'n_epochs': 90, 'lr_all': 0.002, 'reg_all': 0.2, 'random_state': 32}\n",
      "\n",
      "Training set RMSE for each hyper-parameter combination:\n",
      "1.1247 (+/-0.0007) for {'n_epochs': 30, 'lr_all': 0.001, 'reg_all': 0.1, 'random_state': 32}\n",
      "1.1254 (+/-0.0008) for {'n_epochs': 30, 'lr_all': 0.001, 'reg_all': 0.2, 'random_state': 32}\n",
      "1.1271 (+/-0.0009) for {'n_epochs': 30, 'lr_all': 0.001, 'reg_all': 0.3, 'random_state': 32}\n",
      "1.1313 (+/-0.0010) for {'n_epochs': 30, 'lr_all': 0.001, 'reg_all': 0.5, 'random_state': 32}\n",
      "1.1094 (+/-0.0012) for {'n_epochs': 30, 'lr_all': 0.002, 'reg_all': 0.1, 'random_state': 32}\n",
      "1.1098 (+/-0.0013) for {'n_epochs': 30, 'lr_all': 0.002, 'reg_all': 0.2, 'random_state': 32}\n",
      "1.1116 (+/-0.0013) for {'n_epochs': 30, 'lr_all': 0.002, 'reg_all': 0.3, 'random_state': 32}\n",
      "1.1168 (+/-0.0013) for {'n_epochs': 30, 'lr_all': 0.002, 'reg_all': 0.5, 'random_state': 32}\n",
      "1.1045 (+/-0.0020) for {'n_epochs': 30, 'lr_all': 0.005, 'reg_all': 0.1, 'random_state': 32}\n",
      "1.1022 (+/-0.0019) for {'n_epochs': 30, 'lr_all': 0.005, 'reg_all': 0.2, 'random_state': 32}\n",
      "1.1035 (+/-0.0018) for {'n_epochs': 30, 'lr_all': 0.005, 'reg_all': 0.3, 'random_state': 32}\n",
      "1.1084 (+/-0.0017) for {'n_epochs': 30, 'lr_all': 0.005, 'reg_all': 0.5, 'random_state': 32}\n",
      "1.1126 (+/-0.0011) for {'n_epochs': 50, 'lr_all': 0.001, 'reg_all': 0.1, 'random_state': 32}\n",
      "1.1132 (+/-0.0011) for {'n_epochs': 50, 'lr_all': 0.001, 'reg_all': 0.2, 'random_state': 32}\n",
      "1.1150 (+/-0.0012) for {'n_epochs': 50, 'lr_all': 0.001, 'reg_all': 0.3, 'random_state': 32}\n",
      "1.1200 (+/-0.0013) for {'n_epochs': 50, 'lr_all': 0.001, 'reg_all': 0.5, 'random_state': 32}\n",
      "1.1042 (+/-0.0017) for {'n_epochs': 50, 'lr_all': 0.002, 'reg_all': 0.1, 'random_state': 32}\n",
      "1.1036 (+/-0.0016) for {'n_epochs': 50, 'lr_all': 0.002, 'reg_all': 0.2, 'random_state': 32}\n",
      "1.1054 (+/-0.0016) for {'n_epochs': 50, 'lr_all': 0.002, 'reg_all': 0.3, 'random_state': 32}\n",
      "1.1106 (+/-0.0016) for {'n_epochs': 50, 'lr_all': 0.002, 'reg_all': 0.5, 'random_state': 32}\n",
      "1.1102 (+/-0.0024) for {'n_epochs': 50, 'lr_all': 0.005, 'reg_all': 0.1, 'random_state': 32}\n",
      "1.1031 (+/-0.0021) for {'n_epochs': 50, 'lr_all': 0.005, 'reg_all': 0.2, 'random_state': 32}\n",
      "1.1037 (+/-0.0020) for {'n_epochs': 50, 'lr_all': 0.005, 'reg_all': 0.3, 'random_state': 32}\n",
      "1.1079 (+/-0.0018) for {'n_epochs': 50, 'lr_all': 0.005, 'reg_all': 0.5, 'random_state': 32}\n",
      "1.1072 (+/-0.0013) for {'n_epochs': 70, 'lr_all': 0.001, 'reg_all': 0.1, 'random_state': 32}\n",
      "1.1074 (+/-0.0014) for {'n_epochs': 70, 'lr_all': 0.001, 'reg_all': 0.2, 'random_state': 32}\n",
      "1.1093 (+/-0.0014) for {'n_epochs': 70, 'lr_all': 0.001, 'reg_all': 0.3, 'random_state': 32}\n",
      "1.1145 (+/-0.0014) for {'n_epochs': 70, 'lr_all': 0.001, 'reg_all': 0.5, 'random_state': 32}\n",
      "1.1041 (+/-0.0020) for {'n_epochs': 70, 'lr_all': 0.002, 'reg_all': 0.1, 'random_state': 32}\n",
      "1.1022 (+/-0.0018) for {'n_epochs': 70, 'lr_all': 0.002, 'reg_all': 0.2, 'random_state': 32}\n",
      "1.1036 (+/-0.0018) for {'n_epochs': 70, 'lr_all': 0.002, 'reg_all': 0.3, 'random_state': 32}\n",
      "1.1086 (+/-0.0017) for {'n_epochs': 70, 'lr_all': 0.002, 'reg_all': 0.5, 'random_state': 32}\n",
      "1.1159 (+/-0.0026) for {'n_epochs': 70, 'lr_all': 0.005, 'reg_all': 0.1, 'random_state': 32}\n",
      "1.1046 (+/-0.0021) for {'n_epochs': 70, 'lr_all': 0.005, 'reg_all': 0.2, 'random_state': 32}\n",
      "1.1045 (+/-0.0020) for {'n_epochs': 70, 'lr_all': 0.005, 'reg_all': 0.3, 'random_state': 32}\n",
      "1.1082 (+/-0.0019) for {'n_epochs': 70, 'lr_all': 0.005, 'reg_all': 0.5, 'random_state': 32}\n",
      "1.1048 (+/-0.0016) for {'n_epochs': 90, 'lr_all': 0.001, 'reg_all': 0.1, 'random_state': 32}\n",
      "1.1045 (+/-0.0016) for {'n_epochs': 90, 'lr_all': 0.001, 'reg_all': 0.2, 'random_state': 32}\n",
      "1.1063 (+/-0.0016) for {'n_epochs': 90, 'lr_all': 0.001, 'reg_all': 0.3, 'random_state': 32}\n",
      "1.1116 (+/-0.0015) for {'n_epochs': 90, 'lr_all': 0.001, 'reg_all': 0.5, 'random_state': 32}\n",
      "1.1057 (+/-0.0022) for {'n_epochs': 90, 'lr_all': 0.002, 'reg_all': 0.1, 'random_state': 32}\n",
      "1.1021 (+/-0.0020) for {'n_epochs': 90, 'lr_all': 0.002, 'reg_all': 0.2, 'random_state': 32}\n",
      "1.1032 (+/-0.0019) for {'n_epochs': 90, 'lr_all': 0.002, 'reg_all': 0.3, 'random_state': 32}\n",
      "1.1080 (+/-0.0018) for {'n_epochs': 90, 'lr_all': 0.002, 'reg_all': 0.5, 'random_state': 32}\n",
      "1.1192 (+/-0.0026) for {'n_epochs': 90, 'lr_all': 0.005, 'reg_all': 0.1, 'random_state': 32}\n",
      "1.1059 (+/-0.0021) for {'n_epochs': 90, 'lr_all': 0.005, 'reg_all': 0.2, 'random_state': 32}\n",
      "1.1051 (+/-0.0020) for {'n_epochs': 90, 'lr_all': 0.005, 'reg_all': 0.3, 'random_state': 32}\n",
      "1.1084 (+/-0.0019) for {'n_epochs': 90, 'lr_all': 0.005, 'reg_all': 0.5, 'random_state': 32}\n",
      "\n",
      "Test set  RMSE: 1.0917\n",
      "Wall time: 34min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "param_grid = {'n_epochs':[30,50,70,90], 'lr_all': [.001,.002, 0.005], \n",
    "              'reg_all': [ .1, .2, .3, .5], 'random_state':[32]}\n",
    "training_test_algorithm(train_raw_ratings, test_raw_ratings, SVD, param_grid, n_cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyper-parameters: {'n_epochs': 80, 'lr_all': 0.002, 'reg_all': 0.2, 'random_state': 32}\n",
      "\n",
      "Training set RMSE for each hyper-parameter combination:\n",
      "1.1054 (+/-0.0022) for {'n_epochs': 80, 'lr_all': 0.001, 'reg_all': 0.1, 'random_state': 32}\n",
      "1.1055 (+/-0.0021) for {'n_epochs': 80, 'lr_all': 0.001, 'reg_all': 0.2, 'random_state': 32}\n",
      "1.1074 (+/-0.0021) for {'n_epochs': 80, 'lr_all': 0.001, 'reg_all': 0.3, 'random_state': 32}\n",
      "1.1042 (+/-0.0025) for {'n_epochs': 80, 'lr_all': 0.002, 'reg_all': 0.1, 'random_state': 32}\n",
      "1.1017 (+/-0.0024) for {'n_epochs': 80, 'lr_all': 0.002, 'reg_all': 0.2, 'random_state': 32}\n",
      "1.1031 (+/-0.0023) for {'n_epochs': 80, 'lr_all': 0.002, 'reg_all': 0.3, 'random_state': 32}\n",
      "1.1168 (+/-0.0028) for {'n_epochs': 80, 'lr_all': 0.005, 'reg_all': 0.1, 'random_state': 32}\n",
      "1.1049 (+/-0.0028) for {'n_epochs': 80, 'lr_all': 0.005, 'reg_all': 0.2, 'random_state': 32}\n",
      "1.1045 (+/-0.0025) for {'n_epochs': 80, 'lr_all': 0.005, 'reg_all': 0.3, 'random_state': 32}\n",
      "1.1044 (+/-0.0022) for {'n_epochs': 90, 'lr_all': 0.001, 'reg_all': 0.1, 'random_state': 32}\n",
      "1.1043 (+/-0.0021) for {'n_epochs': 90, 'lr_all': 0.001, 'reg_all': 0.2, 'random_state': 32}\n",
      "1.1061 (+/-0.0021) for {'n_epochs': 90, 'lr_all': 0.001, 'reg_all': 0.3, 'random_state': 32}\n",
      "1.1051 (+/-0.0025) for {'n_epochs': 90, 'lr_all': 0.002, 'reg_all': 0.1, 'random_state': 32}\n",
      "1.1018 (+/-0.0024) for {'n_epochs': 90, 'lr_all': 0.002, 'reg_all': 0.2, 'random_state': 32}\n",
      "1.1030 (+/-0.0023) for {'n_epochs': 90, 'lr_all': 0.002, 'reg_all': 0.3, 'random_state': 32}\n",
      "1.1182 (+/-0.0028) for {'n_epochs': 90, 'lr_all': 0.005, 'reg_all': 0.1, 'random_state': 32}\n",
      "1.1055 (+/-0.0028) for {'n_epochs': 90, 'lr_all': 0.005, 'reg_all': 0.2, 'random_state': 32}\n",
      "1.1048 (+/-0.0025) for {'n_epochs': 90, 'lr_all': 0.005, 'reg_all': 0.3, 'random_state': 32}\n",
      "1.1038 (+/-0.0023) for {'n_epochs': 100, 'lr_all': 0.001, 'reg_all': 0.1, 'random_state': 32}\n",
      "1.1034 (+/-0.0022) for {'n_epochs': 100, 'lr_all': 0.001, 'reg_all': 0.2, 'random_state': 32}\n",
      "1.1052 (+/-0.0021) for {'n_epochs': 100, 'lr_all': 0.001, 'reg_all': 0.3, 'random_state': 32}\n",
      "1.1063 (+/-0.0026) for {'n_epochs': 100, 'lr_all': 0.002, 'reg_all': 0.1, 'random_state': 32}\n",
      "1.1020 (+/-0.0025) for {'n_epochs': 100, 'lr_all': 0.002, 'reg_all': 0.2, 'random_state': 32}\n",
      "1.1030 (+/-0.0024) for {'n_epochs': 100, 'lr_all': 0.002, 'reg_all': 0.3, 'random_state': 32}\n",
      "1.1193 (+/-0.0028) for {'n_epochs': 100, 'lr_all': 0.005, 'reg_all': 0.1, 'random_state': 32}\n",
      "1.1061 (+/-0.0029) for {'n_epochs': 100, 'lr_all': 0.005, 'reg_all': 0.2, 'random_state': 32}\n",
      "1.1050 (+/-0.0025) for {'n_epochs': 100, 'lr_all': 0.005, 'reg_all': 0.3, 'random_state': 32}\n",
      "\n",
      "Test set  RMSE: 1.0916\n",
      "Wall time: 29min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "param_grid = {'n_epochs':[80,90,100], 'lr_all': [.001,.002, 0.005], \n",
    "              'reg_all': [ .1, .2, .3], 'random_state':[32]}\n",
    "training_test_algorithm(train_raw_ratings, test_raw_ratings, SVD, param_grid, n_cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyper-parameters: {'n_epochs': 80, 'lr_all': 0.002, 'reg_all': 0.2, 'random_state': 32}\n",
      "\n",
      "Training set RMSE for each hyper-parameter combination:\n",
      "1.1068 (+/-0.0063) for {'n_epochs': 70, 'lr_all': 0.001, 'reg_all': 0.15, 'random_state': 32}\n",
      "1.1073 (+/-0.0063) for {'n_epochs': 70, 'lr_all': 0.001, 'reg_all': 0.2, 'random_state': 32}\n",
      "1.1081 (+/-0.0063) for {'n_epochs': 70, 'lr_all': 0.001, 'reg_all': 0.25, 'random_state': 32}\n",
      "1.1022 (+/-0.0058) for {'n_epochs': 70, 'lr_all': 0.002, 'reg_all': 0.15, 'random_state': 32}\n",
      "1.1022 (+/-0.0059) for {'n_epochs': 70, 'lr_all': 0.002, 'reg_all': 0.2, 'random_state': 32}\n",
      "1.1027 (+/-0.0060) for {'n_epochs': 70, 'lr_all': 0.002, 'reg_all': 0.25, 'random_state': 32}\n",
      "1.1075 (+/-0.0055) for {'n_epochs': 70, 'lr_all': 0.005, 'reg_all': 0.15, 'random_state': 32}\n",
      "1.1048 (+/-0.0058) for {'n_epochs': 70, 'lr_all': 0.005, 'reg_all': 0.2, 'random_state': 32}\n",
      "1.1043 (+/-0.0059) for {'n_epochs': 70, 'lr_all': 0.005, 'reg_all': 0.25, 'random_state': 32}\n",
      "1.1052 (+/-0.0062) for {'n_epochs': 80, 'lr_all': 0.001, 'reg_all': 0.15, 'random_state': 32}\n",
      "1.1056 (+/-0.0062) for {'n_epochs': 80, 'lr_all': 0.001, 'reg_all': 0.2, 'random_state': 32}\n",
      "1.1064 (+/-0.0062) for {'n_epochs': 80, 'lr_all': 0.001, 'reg_all': 0.25, 'random_state': 32}\n",
      "1.1023 (+/-0.0057) for {'n_epochs': 80, 'lr_all': 0.002, 'reg_all': 0.15, 'random_state': 32}\n",
      "1.1021 (+/-0.0059) for {'n_epochs': 80, 'lr_all': 0.002, 'reg_all': 0.2, 'random_state': 32}\n",
      "1.1026 (+/-0.0059) for {'n_epochs': 80, 'lr_all': 0.002, 'reg_all': 0.25, 'random_state': 32}\n",
      "1.1088 (+/-0.0056) for {'n_epochs': 80, 'lr_all': 0.005, 'reg_all': 0.15, 'random_state': 32}\n",
      "1.1055 (+/-0.0058) for {'n_epochs': 80, 'lr_all': 0.005, 'reg_all': 0.2, 'random_state': 32}\n",
      "1.1048 (+/-0.0059) for {'n_epochs': 80, 'lr_all': 0.005, 'reg_all': 0.25, 'random_state': 32}\n",
      "1.1040 (+/-0.0061) for {'n_epochs': 90, 'lr_all': 0.001, 'reg_all': 0.15, 'random_state': 32}\n",
      "1.1044 (+/-0.0061) for {'n_epochs': 90, 'lr_all': 0.001, 'reg_all': 0.2, 'random_state': 32}\n",
      "1.1052 (+/-0.0061) for {'n_epochs': 90, 'lr_all': 0.001, 'reg_all': 0.25, 'random_state': 32}\n",
      "1.1026 (+/-0.0057) for {'n_epochs': 90, 'lr_all': 0.002, 'reg_all': 0.15, 'random_state': 32}\n",
      "1.1022 (+/-0.0058) for {'n_epochs': 90, 'lr_all': 0.002, 'reg_all': 0.2, 'random_state': 32}\n",
      "1.1026 (+/-0.0059) for {'n_epochs': 90, 'lr_all': 0.002, 'reg_all': 0.25, 'random_state': 32}\n",
      "1.1100 (+/-0.0056) for {'n_epochs': 90, 'lr_all': 0.005, 'reg_all': 0.15, 'random_state': 32}\n",
      "1.1062 (+/-0.0058) for {'n_epochs': 90, 'lr_all': 0.005, 'reg_all': 0.2, 'random_state': 32}\n",
      "1.1052 (+/-0.0059) for {'n_epochs': 90, 'lr_all': 0.005, 'reg_all': 0.25, 'random_state': 32}\n",
      "\n",
      "Test set  RMSE: 1.0916\n",
      "Wall time: 26min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "param_grid = {'n_epochs':[70,80,90], 'lr_all': [.001,.002, 0.005], \n",
    "              'reg_all': [ .15, .2, .25], 'random_state':[32]}\n",
    "training_test_algorithm(train_raw_ratings, test_raw_ratings, SVD, param_grid, n_cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyper-parameters: {'n_epochs': 80, 'lr_all': 0.002, 'reg_all': 0.18, 'random_state': 32}\n",
      "\n",
      "Training set RMSE for each hyper-parameter combination:\n",
      "1.1016 (+/-0.0048) for {'n_epochs': 80, 'lr_all': 0.002, 'reg_all': 0.18, 'random_state': 32}\n",
      "1.1016 (+/-0.0048) for {'n_epochs': 80, 'lr_all': 0.002, 'reg_all': 0.2, 'random_state': 32}\n",
      "1.1017 (+/-0.0048) for {'n_epochs': 80, 'lr_all': 0.002, 'reg_all': 0.22, 'random_state': 32}\n",
      "\n",
      "Test set  RMSE: 1.0914\n",
      "Wall time: 4min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "param_grid = {'n_epochs':[80], 'lr_all': [.002], \n",
    "              'reg_all': [ .18, .2, .22], 'random_state':[32]}\n",
    "training_test_algorithm(train_raw_ratings, test_raw_ratings, SVD, param_grid, n_cv=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I found some smaller number of epochs are as good as big ones below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyper-parameters: {'n_epochs': 30, 'lr_all': 0.005, 'reg_all': 0.2, 'random_state': 32}\n",
      "\n",
      "Training set RMSE for each hyper-parameter combination:\n",
      "1.1024 (+/-0.0037) for {'n_epochs': 30, 'lr_all': 0.005, 'reg_all': 0.15, 'random_state': 32}\n",
      "1.1022 (+/-0.0036) for {'n_epochs': 30, 'lr_all': 0.005, 'reg_all': 0.2, 'random_state': 32}\n",
      "1.1035 (+/-0.0034) for {'n_epochs': 30, 'lr_all': 0.005, 'reg_all': 0.3, 'random_state': 32}\n",
      "1.1084 (+/-0.0032) for {'n_epochs': 30, 'lr_all': 0.005, 'reg_all': 0.5, 'random_state': 32}\n",
      "\n",
      "Test set  RMSE: 1.0916\n",
      "Wall time: 2min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "param_grid = {'n_epochs':[30], 'lr_all': [0.005], \n",
    "              'reg_all': [.15,.2,.3,.5], 'random_state':[32]}\n",
    "training_test_algorithm(train_raw_ratings, test_raw_ratings, SVD, param_grid, n_cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyper-parameters: {'n_epochs': 30, 'lr_all': 0.005, 'reg_all': 0.18, 'random_state': 32}\n",
      "\n",
      "Training set RMSE for each hyper-parameter combination:\n",
      "1.1021 (+/-0.0028) for {'n_epochs': 30, 'lr_all': 0.005, 'reg_all': 0.18, 'random_state': 32}\n",
      "1.1021 (+/-0.0027) for {'n_epochs': 30, 'lr_all': 0.005, 'reg_all': 0.2, 'random_state': 32}\n",
      "1.1026 (+/-0.0027) for {'n_epochs': 30, 'lr_all': 0.005, 'reg_all': 0.25, 'random_state': 32}\n",
      "\n",
      "Test set  RMSE: 1.0914\n",
      "Wall time: 2min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "param_grid = {'n_epochs':[30], 'lr_all': [0.005], \n",
    "              'reg_all': [.18,.2,.25], 'random_state':[32]}\n",
    "training_test_algorithm(train_raw_ratings, test_raw_ratings, SVD, param_grid, n_cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyper-parameters: {'n_epochs': 30, 'lr_all': 0.005, 'reg_all': 0.18, 'random_state': 32}\n",
      "\n",
      "Training set RMSE for each hyper-parameter combination:\n",
      "1.1176 (+/-0.0034) for {'n_epochs': 20, 'lr_all': 0.002, 'reg_all': 0.17, 'random_state': 32}\n",
      "1.1177 (+/-0.0034) for {'n_epochs': 20, 'lr_all': 0.002, 'reg_all': 0.18, 'random_state': 32}\n",
      "1.1178 (+/-0.0034) for {'n_epochs': 20, 'lr_all': 0.002, 'reg_all': 0.19, 'random_state': 32}\n",
      "1.1180 (+/-0.0034) for {'n_epochs': 20, 'lr_all': 0.002, 'reg_all': 0.2, 'random_state': 32}\n",
      "1.1035 (+/-0.0029) for {'n_epochs': 20, 'lr_all': 0.005, 'reg_all': 0.17, 'random_state': 32}\n",
      "1.1035 (+/-0.0028) for {'n_epochs': 20, 'lr_all': 0.005, 'reg_all': 0.18, 'random_state': 32}\n",
      "1.1036 (+/-0.0028) for {'n_epochs': 20, 'lr_all': 0.005, 'reg_all': 0.19, 'random_state': 32}\n",
      "1.1037 (+/-0.0028) for {'n_epochs': 20, 'lr_all': 0.005, 'reg_all': 0.2, 'random_state': 32}\n",
      "1.1094 (+/-0.0032) for {'n_epochs': 30, 'lr_all': 0.002, 'reg_all': 0.17, 'random_state': 32}\n",
      "1.1095 (+/-0.0031) for {'n_epochs': 30, 'lr_all': 0.002, 'reg_all': 0.18, 'random_state': 32}\n",
      "1.1096 (+/-0.0031) for {'n_epochs': 30, 'lr_all': 0.002, 'reg_all': 0.19, 'random_state': 32}\n",
      "1.1098 (+/-0.0031) for {'n_epochs': 30, 'lr_all': 0.002, 'reg_all': 0.2, 'random_state': 32}\n",
      "1.1021 (+/-0.0027) for {'n_epochs': 30, 'lr_all': 0.005, 'reg_all': 0.17, 'random_state': 32}\n",
      "1.1021 (+/-0.0027) for {'n_epochs': 30, 'lr_all': 0.005, 'reg_all': 0.18, 'random_state': 32}\n",
      "1.1021 (+/-0.0027) for {'n_epochs': 30, 'lr_all': 0.005, 'reg_all': 0.19, 'random_state': 32}\n",
      "1.1021 (+/-0.0027) for {'n_epochs': 30, 'lr_all': 0.005, 'reg_all': 0.2, 'random_state': 32}\n",
      "1.1054 (+/-0.0030) for {'n_epochs': 40, 'lr_all': 0.002, 'reg_all': 0.17, 'random_state': 32}\n",
      "1.1055 (+/-0.0030) for {'n_epochs': 40, 'lr_all': 0.002, 'reg_all': 0.18, 'random_state': 32}\n",
      "1.1056 (+/-0.0030) for {'n_epochs': 40, 'lr_all': 0.002, 'reg_all': 0.19, 'random_state': 32}\n",
      "1.1057 (+/-0.0030) for {'n_epochs': 40, 'lr_all': 0.002, 'reg_all': 0.2, 'random_state': 32}\n",
      "1.1026 (+/-0.0027) for {'n_epochs': 40, 'lr_all': 0.005, 'reg_all': 0.17, 'random_state': 32}\n",
      "1.1025 (+/-0.0027) for {'n_epochs': 40, 'lr_all': 0.005, 'reg_all': 0.18, 'random_state': 32}\n",
      "1.1024 (+/-0.0027) for {'n_epochs': 40, 'lr_all': 0.005, 'reg_all': 0.19, 'random_state': 32}\n",
      "1.1024 (+/-0.0027) for {'n_epochs': 40, 'lr_all': 0.005, 'reg_all': 0.2, 'random_state': 32}\n",
      "\n",
      "Test set  RMSE: 1.0914\n",
      "Wall time: 10min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "param_grid = {'n_epochs':[20,30,40], 'lr_all': [.002, 0.005], \n",
    "              'reg_all': [.17,.18,.19,.2], 'random_state':[32]}\n",
    "training_test_algorithm(train_raw_ratings, test_raw_ratings, SVD, param_grid, n_cv=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVDpp algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyper-parameters: {'random_state': 32}\n",
      "\n",
      "Training set RMSE for each hyper-parameter combination:\n",
      "1.1175 (+/-0.0042) for {'random_state': 32}\n",
      "\n",
      "Test set  RMSE: 1.1108\n",
      "Wall time: 9min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "param_grid = {'random_state':[32]}\n",
    "training_test_algorithm(train_raw_ratings, test_raw_ratings, SVDpp, param_grid, n_cv=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVDpp is so much slower and higher in RMSE than SVD when both are not tuned, so I will not use this algorithm. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NMF algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyper-parameters: {'random_state': 32}\n",
      "\n",
      "Training set RMSE for each hyper-parameter combination:\n",
      "1.2139 (+/-0.0019) for {'random_state': 32}\n",
      "\n",
      "Test set  RMSE: 1.1755\n",
      "Wall time: 1min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "param_grid = {'random_state':[32]}\n",
    "training_test_algorithm(train_raw_ratings, test_raw_ratings, NMF, param_grid, n_cv=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- NMF is much worse in RMSE and slightly slower than SVD when not tuned, so I will not use this algorithm.\n",
    "- I also tried 4 KNN-based algorithms in the Surprise, but they threw a memory error while I'm using only 50% of 24GB memory. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3'></a>\n",
    "### Content-Based Filtering algorithms "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "Surprise\n",
    "https://surprise.readthedocs.io/en/stable/index.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
